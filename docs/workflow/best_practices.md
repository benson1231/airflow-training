# Airflow DAG Best Practices

**2025.10.22**

---

## ğŸ¯ ç›®æ¨™
æä¾›åœ¨è¨­è¨ˆèˆ‡ç¶­è­· Apache Airflow DAG æ™‚çš„å¯¦å‹™å»ºè­°ï¼Œå¹«åŠ©é–‹ç™¼è€…æ’°å¯« **å¯è®€æ€§é«˜ã€å¯ç¶­è­·ã€å¯é‡ç¾** çš„å·¥ä½œæµç¨‹ã€‚

---

## ğŸ§© 1. DAG çµæ§‹è¨­è¨ˆ

### âœ… å»ºè­°
- **ä¸€å€‹ DAG å°æ‡‰ä¸€å€‹é‚è¼¯æµç¨‹**ï¼Œä¾‹å¦‚ ETLã€å ±è¡¨ç”Ÿæˆæˆ–åˆ†æä»»å‹™ã€‚
- DAG IDã€task_id å‘½åéœ€ç°¡æ½”ä¸¦å…·æè¿°æ€§ï¼Œä¾‹å¦‚ï¼š`etl_daily_sales`ã€`load_to_bigquery`ã€‚
- å°‡ **é‡è¤‡ä»»å‹™æ¨¡çµ„åŒ–**ï¼Œå¯å°è£æˆ Python å‡½å¼æˆ–è‡ªè¨‚ Operatorã€‚
- å°‡ **DAG å®šç¾©èˆ‡ä»»å‹™é‚è¼¯åˆ†é›¢**ï¼š
  - DAG ç”¨æ–¼è¨­å®šçµæ§‹èˆ‡æ’ç¨‹ã€‚
  - ä»»å‹™é‚è¼¯æ”¾åœ¨ç¨ç«‹æ¨¡çµ„ä¸­ï¼ˆä¾‹å¦‚ `tasks/transform.py`ï¼‰ã€‚

### âš ï¸ é¿å…
- åœ¨ DAG æª”ä¸­ç›´æ¥å¯«å¤§é‡æ¥­å‹™é‚è¼¯æˆ–è³‡æ–™è™•ç†ç¨‹å¼ç¢¼ã€‚
- åœ¨ DAG åˆå§‹åŒ–éšæ®µè®€å–å¤–éƒ¨ API æˆ–å¤§å‹æª”æ¡ˆï¼ˆæ‡‰æ”¾å…¥ task ä¸­ï¼‰ã€‚

---

## â±ï¸ 2. æ’ç¨‹èˆ‡æ™‚é–“ç®¡ç†

### âœ… å»ºè­°
- è¨­å®š `start_date` ä¸¦å›ºå®šåœ¨ **éå»æ™‚é–“**ï¼ˆé¿å…éé æœŸè£œè·‘ï¼‰ã€‚
- ä½¿ç”¨ `catchup=False` é¿å…ä¸å¿…è¦çš„æ­·å²è£œåŸ·è¡Œï¼ˆé™¤éç¢ºå¯¦éœ€è¦ backfillï¼‰ã€‚
- `schedule` å¯ç”¨ cron æˆ– presetsï¼Œä¾‹å¦‚ï¼š`@daily`ã€`@weekly`ã€‚
- ä½¿ç”¨ `max_active_runs=1` æ§åˆ¶åŒæ™‚åŸ·è¡Œçš„ DAG Run æ•¸é‡ã€‚

### âš ï¸ é¿å…
- å°‡ `start_date` è¨­ç‚ºå‹•æ…‹æ™‚é–“ï¼ˆå¦‚ `datetime.now()`ï¼‰ã€‚
- ä¸è¨­å®š `catchup` å°è‡´æ„å¤–è§¸ç™¼æ•¸ç™¾å€‹æ­·å² DAG Runã€‚

---

## ğŸ” 3. ä»»å‹™æ’°å¯«èˆ‡ä¾è³´è¨­è¨ˆ

### âœ… å»ºè­°
- ä½¿ç”¨ **TaskFlow API**ï¼ˆ`@task` / `@task_group`ï¼‰å–ä»£èˆŠå¼ Operator å®šç¾©ã€‚
- æ˜ç¢ºè¨­å®šä»»å‹™ä¾è³´ï¼š
  ```python
  extract() >> transform() >> load()
  ```
- è‹¥ä»»å‹™ä¹‹é–“éœ€å‚³éè³‡æ–™ï¼Œä½¿ç”¨ **XComï¼ˆè‡ªå‹•ï¼‰æˆ–å¤–éƒ¨å„²å­˜**ã€‚
- è¨­å®šåˆç†çš„ `retries` èˆ‡ `retry_delay`ï¼Œé¿å…çŸ­æ™‚é–“é‡è¤‡å¤±æ•—ã€‚

### âš™ï¸ å¯¦ä¾‹
```python
@dag(schedule='@daily', start_date=datetime(2024,1,1), catchup=False)
def etl_pipeline():

    @task(retries=2, retry_delay=timedelta(minutes=5))
    def extract():
        return get_data_from_api()

    @task()
    def transform(data):
        return clean_data(data)

    @task()
    def load(data):
        write_to_db(data)

    extract() >> transform() >> load()
```

---

## ğŸ“¦ 4. è®Šæ•¸èˆ‡é€£ç·šç®¡ç†

### âœ… å»ºè­°
- ä½¿ç”¨ Airflow **Variables** æˆ– **Connections** ç®¡ç†ç’°å¢ƒè¨­å®šã€‚
- æ©Ÿå¯†è³‡è¨Šä¸æ‡‰ç¡¬ç·¨ç¢¼åœ¨ DAG æª”ä¸­ã€‚
- å¯çµåˆ `.env` æˆ– Secrets Backendï¼ˆVaultã€AWS Secret Managerï¼‰ã€‚

### âš™ï¸ ç¯„ä¾‹
```python
from airflow.models import Variable
api_key = Variable.get("API_KEY")
```

---

## ğŸ“Š 5. Logging èˆ‡ç›£æ§

### âœ… å»ºè­°
- åˆ©ç”¨ Airflow Web UI æª¢è¦–å„ä»»å‹™ logã€‚
- è¨­å®š log rotationï¼ˆé¿å…é•·æœŸå †ç©ï¼‰ã€‚
- æ•´åˆ Slack / Email alert é€šçŸ¥éŒ¯èª¤ï¼š
  ```python
  default_args = {
      'email': ['team@domain.com'],
      'email_on_failure': True,
      'retries': 1
  }
  ```

---

## ğŸ§ª 6. æ¸¬è©¦èˆ‡é–‹ç™¼æµç¨‹

### âœ… å»ºè­°
- æœ¬åœ°é–‹ç™¼å¯ä½¿ç”¨ `airflow dags test <dag_id>` é©—è­‰ DAG æµç¨‹ã€‚
- ä½¿ç”¨ `pytest` æ­é… `airflow.models.DAG` é€²è¡Œå–®å…ƒæ¸¬è©¦ã€‚
- ç¢ºä¿ DAG æª”èƒ½åœ¨ä¸é€£ç·šå¤–éƒ¨æœå‹™çš„æƒ…æ³ä¸‹è¼‰å…¥ï¼ˆimport å®‰å…¨ï¼‰ã€‚

---

## ğŸš€ 7. æ•ˆèƒ½èˆ‡ç¶­è­·

### âœ… å»ºè­°
- å®šæœŸæ¸…ç†èˆŠä»»å‹™èˆ‡æ—¥èªŒ (`airflow db clean`)ã€‚
- æ‹†åˆ†å¤§å‹ DAG ç‚ºå¤šå€‹å° DAGï¼Œä¸¦ä»¥ **TriggerDagRunOperator** ä¸²æ¥ã€‚
- é€é **TaskGroup / Dynamic Task Mapping** é™ä½é‡è¤‡ä»£ç¢¼ã€‚

---

## ğŸ“˜ å°çµ
| é¢å‘ | æ ¸å¿ƒåŸå‰‡ |
|-------|------------|
| DAG çµæ§‹ | å–®ä¸€è·è²¬ã€æ¨¡çµ„åŒ–ã€å¯é‡ç”¨ |
| æ’ç¨‹ | å›ºå®š start_dateã€æ§åˆ¶ catchup èˆ‡ä½µç™¼ |
| ä»»å‹™ | ä½¿ç”¨ TaskFlow APIã€æ˜ç¢ºä¾è³´ã€è¨­å®š retries |
| å®‰å…¨æ€§ | æ©Ÿå¯†è³‡æ–™é›†ä¸­ç®¡ç†ã€ä¸ç¡¬ç·¨ç¢¼ |
| ç›£æ§ | ä½¿ç”¨ logã€é€šçŸ¥èˆ‡ metrics |
| æ¸¬è©¦ | ä½¿ç”¨ airflow test èˆ‡ pytest é©—è­‰ |
| ç¶­é‹ | æ¸…ç†è³‡æ–™ã€æ‹†åˆ†å¤§ DAGã€å‹•æ…‹ä»»å‹™ç”Ÿæˆ |

---

> ğŸ’¡ **å»ºè­°åšæ³•**ï¼šå»ºç«‹ä¸€å€‹ `templates/` æˆ– `common_tasks/` è³‡æ–™å¤¾ï¼Œç”¨ä»¥å„²å­˜é€šç”¨çš„ä»»å‹™æ¨¡çµ„ã€é€šçŸ¥å‡½å¼ã€éŒ¯èª¤è™•ç†é‚è¼¯ï¼Œè®“æ‰€æœ‰ DAG éƒ½èƒ½å…±ç”¨ç›¸åŒæ¨™æº–ï¼Œæå‡å¯ç¶­è­·æ€§ã€‚